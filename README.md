# nihongo-it-anki

Japanese IT/Software Engineering Vocabulary Anki Deck with Audio

Learn 1000 essential IT vocabulary words used in American tech companies, with native Japanese audio generated by Kokoro TTS.

## Features

- **1000 vocabulary sentences** organized into 6 tiers by frequency
- **Japanese audio** generated with Kokoro TTS (male voice)
- **2-card design** for comprehensive learning (comprehension + production)
- **Progressive learning** - start with daily essentials, advance to specialized terms
- **Accurate pronunciation** - furigana-based TTS preprocessing for correct kanji readings
- **Key vocabulary meanings** - each card shows the key word with its English translation

## Tier Structure

| Tier | Words | Count | Focus |
|------|-------|-------|-------|
| Tier 1 | 1-150 | 150 | Daily Essentials (communication, git, code actions) |
| Tier 2 | 151-350 | 200 | High Frequency (agile, APIs, databases, testing) |
| Tier 3 | 351-600 | 250 | Medium Frequency (code review, architecture, AWS, monitoring) |
| Tier 4 | 601-800 | 200 | Specialized (security, debugging, documentation) |
| Tier 5 | 801-900 | 100 | Communication & Soft Skills |
| Tier 6 | 901-1000 | 100 | Presentations & Advanced |

## Anki Card Design

This deck uses a **2-card design** - each vocabulary item generates two cards for comprehensive learning:

### Card A: Comprehension (Listening + Reading)

```
┌─────────────────────────────────────────────┐
│ FRONT                                       │
│                                             │
│  [Audio auto-plays]                         │
│  機能は完了しレビュー準備ができました。          │
│  [Status]                                   │
├─────────────────────────────────────────────┤
│ BACK                                        │
│                                             │
│  The feature is done and ready for review.  │
│  機能【きのう】は完了【かんりょう】し...         │
│  Key: 完了 (completed)                       │
└─────────────────────────────────────────────┘
```

**Purpose**: Train listening comprehension and kanji recognition. Audio plays first, then you read the Japanese and try to understand before flipping.

### Card B: Production (English → Japanese)

```
┌─────────────────────────────────────────────┐
│ FRONT                                       │
│                                             │
│  "The feature is done and ready for review."│
│  How do you say this in Japanese?           │
│  Hint: 機... (Status)                        │
├─────────────────────────────────────────────┤
│ BACK                                        │
│                                             │
│  機能は完了しレビュー準備ができました。          │
│  [Audio plays]                              │
│  機能【きのう】は完了【かんりょう】し...         │
└─────────────────────────────────────────────┘
```

**Purpose**: Active recall - produce Japanese from English context. This is harder but builds speaking/writing ability.

### Why 2-Card Design?

| Card Type | Skill Trained | Difficulty |
|-----------|--------------|------------|
| Comprehension | Listening, Reading, Kanji recognition | Medium |
| Production | Active recall, Speaking, Grammar | Hard |

- **1000 notes → 2000 cards** total
- Comprehension cards build passive understanding
- Production cards build active language ability
- Both are needed for real-world usage

## Prerequisites

- **Python 3.13+**
- **uv** - Fast Python package manager ([install](https://docs.astral.sh/uv/getting-started/installation/))
- **espeak-ng** - Text-to-speech phonemizer
- **Anki** - Flashcard application ([download](https://apps.ankiweb.net/))

### Install espeak-ng

```bash
# Ubuntu/Debian
sudo apt-get install espeak-ng

# macOS
brew install espeak

# Arch Linux
sudo pacman -S espeak-ng
```

## Installation

```bash
# Clone the repository
git clone <repository-url>
cd nihongo-it-anki

# Install dependencies with uv
uv sync
```

## Quick Start

```bash
# 1. Generate audio for tier 1 (takes ~40 minutes)
uv run python scripts/generate_audio.py --tier 1

# 2. Create Anki deck
uv run python scripts/create_deck.py --tier 1

# 3. Import nihongo-it-vocab-tier1.apkg into Anki
```

## Usage

### Generate Audio

Audio files are not included in the repository (they're ~27MB per tier). Generate them locally:

```bash
# Generate audio for a single tier
uv run python scripts/generate_audio.py --tier 1

# Generate audio for all tiers (takes ~4 hours)
uv run python scripts/generate_audio.py --all

# Test with a few samples first
uv run python scripts/sample.py
```

**Audio Generation Details:**
- **Model**: Kokoro-82M via [hexgrad/kokoro](https://github.com/hexgrad/kokoro)
- **Voice**: `jm_kumo` (Japanese male)
- **Format**: WAV 24kHz
- **Speed**: ~8 seconds per sentence
- **Output**: `tier{N}-audio/tier{N}_001.wav` ... `tier{N}_NNN.wav`

### Create Anki Deck

```bash
# Create deck for a single tier
uv run python scripts/create_deck.py --tier 1

# Create decks for all tiers (separate .apkg files)
uv run python scripts/create_deck.py --all

# Create single combined deck with all tiers
uv run python scripts/create_deck.py --combined

# Create deck without audio (for testing)
uv run python scripts/create_deck.py --tier 1 --no-audio
```

**Output Files:**
- `nihongo-it-vocab-tier1.apkg` - Single tier deck
- `nihongo-it-vocab-complete.apkg` - Combined deck (with `--combined`)

### Import into Anki

1. Open Anki
2. File → Import
3. Select the `.apkg` file
4. Cards and audio will be imported automatically

## Project Structure

```
nihongo-it-anki/
├── README.md
├── pyproject.toml
├── uv.lock
├── software-engineering-vocabulary-1000.md  # Original vocabulary list
├── tier1-vocabulary.csv                      # Tier 1 sentences (150)
├── tier2-vocabulary.csv                      # Tier 2 sentences (200)
├── tier3-vocabulary.csv                      # Tier 3 sentences (250)
├── tier4-vocabulary.csv                      # Tier 4 sentences (200)
├── tier5-vocabulary.csv                      # Tier 5 sentences (100)
├── tier6-vocabulary.csv                      # Tier 6 sentences (100)
├── scripts/
│   ├── generate_audio.py                     # Audio generation script
│   ├── create_deck.py                        # Anki deck creation
│   ├── pronunciation.py                      # TTS pronunciation preprocessing
│   ├── add_key_meanings.py                   # Generate KeyMeaning translations
│   └── sample.py                             # Generate sample audio
├── tier*-audio/                              # Generated audio files (gitignored)
└── *.apkg                                    # Generated Anki decks (gitignored)
```

## CSV Format

Each tier CSV contains:

| Column | Description | Example |
|--------|-------------|---------|
| Sentence | Japanese sentence | 機能は完了しレビュー準備ができました。 |
| Translation | English translation | The feature is done and ready for review. |
| Cloze | Key vocabulary word | 完了 |
| Pronunciation | Japanese with furigana | 機能【きのう】は完了【かんりょう】し... |
| Note | Category/context | Status - completed |
| KeyMeaning | English meaning of key word | completed |

## Audio Generation Technical Details

The audio is generated using **Kokoro TTS**, a lightweight 82M parameter text-to-speech model.

### Pronunciation Preprocessing

TTS models often mispronounce kanji and English terms. This project uses a preprocessing pipeline to improve accuracy:

1. **Furigana extraction**: `今日中【きょうじゅう】` → `きょうじゅう`
2. **Number+kanji handling**: `2日【ふつか】` → `ふつか`
3. **English acronym conversion**: `API` → `エーピーアイ`, `EC2` → `イーシーツー`
4. **IT term pronunciation**: 150+ mapped terms (JSON → ジェイソン, AWS → エーダブリューエス)

The Pronunciation column in CSVs contains furigana annotations like `今日中【きょうじゅう】にできますか？`. The TTS receives preprocessed hiragana for accurate readings.

### Available Japanese Voices

| Voice | Type | Quality |
|-------|------|---------|
| `jm_kumo` | Male | C- (default) |
| `jf_alpha` | Female | C+ (best) |
| `jf_gongitsune` | Female | C |
| `jf_nezumi` | Female | C- |
| `jf_tebukuro` | Female | C |

To use a different voice, edit `scripts/generate_audio.py`:

```python
VOICE = 'jf_alpha'  # Change to female voice
```

### First-Time Setup

The first audio generation downloads the Kokoro model (~500MB). Subsequent runs are faster.

### Resource Usage

- **CPU**: High usage during generation (uses PyTorch)
- **Memory**: ~3GB RAM
- **Disk**: ~27MB per tier (WAV files)
- **Time**: ~8 seconds per sentence, ~40 minutes per 150 sentences

## Development

```bash
# Run any Python script
uv run python <script.py>

# Add new dependency
uv add <package>

# Update dependencies
uv sync
```

## Customization

### Change Voice

Edit `VOICE` in `scripts/generate_audio.py` or `scripts/sample.py`.

### Modify Card Styling

Edit the CSS in `scripts/create_deck.py` in the `create_model()` function.

### Add New Vocabulary

1. Edit the appropriate `tier{N}-vocabulary.csv`
2. Regenerate audio: `uv run python scripts/generate_audio.py --tier N`
3. Recreate deck: `uv run python scripts/create_deck.py --tier N`

## Known Limitations

### Particle Prosody

Kokoro TTS sometimes attaches particles (を, に, が) to the following word instead of the preceding word. For example:

- Expected: `今すぐこれを・デプロイする` (particle linked to これ)
- Actual: `今すぐこれ・をデプロイする` (particle linked to デプロイ)

This is a limitation of the TTS model's prosodic phrasing. Natural Japanese speech links particles to the preceding word, but neural TTS models don't always capture this. The audio is still comprehensible but may sound slightly unnatural to trained ears.

## License

MIT

## Credits

- [Kokoro TTS](https://github.com/hexgrad/kokoro) - Text-to-speech model (Apache 2.0)
- [genanki](https://github.com/kerrickstaley/genanki) - Anki deck generation
- [uv](https://github.com/astral-sh/uv) - Python package manager
